Run 'mamba init' to be able to run mamba activate/deactivate
and start a new shell session. Or use conda to activate/deactivate.

/var/spool/slurm/job3844311/slurm_script:31: command not found: module
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

[rank: 0] Global seed set to 1337
[rank: 1] Global seed set to 1337
[rank: 1] Global seed set to 1338
[rank: 0] Global seed set to 1337
Traceback (most recent call last):
  File "/scratch/gilbreth/dchawra/lit-gpt/finetune/adapter_v2.py", line 326, in <module>
    CLI(setup)
  File "/home/dchawra/mambaforge/envs/ml/lib/python3.10/site-packages/jsonargparse/_cli.py", line 85, in CLI
    return _run_component(component, cfg_init)
  File "/home/dchawra/mambaforge/envs/ml/lib/python3.10/site-packages/jsonargparse/_cli.py", line 147, in _run_component
    return component(**cfg)
  File "/scratch/gilbreth/dchawra/lit-gpt/finetune/adapter_v2.py", line 97, in setup
    fabric.launch(main, data_dir, checkpoint_dir, out_dir)
  File "/home/dchawra/mambaforge/envs/ml/lib/python3.10/site-packages/lightning/fabric/fabric.py", line 807, in launch
Traceback (most recent call last):
  File "/scratch/gilbreth/dchawra/lit-gpt/finetune/adapter_v2.py", line 326, in <module>
    return self._wrap_and_launch(function, self, *args, **kwargs)
  File "/home/dchawra/mambaforge/envs/ml/lib/python3.10/site-packages/lightning/fabric/fabric.py", line 889, in _wrap_and_launch
    return to_run(*args, **kwargs)
  File "/home/dchawra/mambaforge/envs/ml/lib/python3.10/site-packages/lightning/fabric/fabric.py", line 894, in _wrap_with_setup
    CLI(setup)
  File "/home/dchawra/mambaforge/envs/ml/lib/python3.10/site-packages/jsonargparse/_cli.py", line 85, in CLI
    return to_run(*args, **kwargs)
  File "/scratch/gilbreth/dchawra/lit-gpt/finetune/adapter_v2.py", line 140, in main
    return _run_component(component, cfg_init)
  File "/home/dchawra/mambaforge/envs/ml/lib/python3.10/site-packages/jsonargparse/_cli.py", line 147, in _run_component
    return component(**cfg)
  File "/scratch/gilbreth/dchawra/lit-gpt/finetune/adapter_v2.py", line 97, in setup
    train(fabric, model, optimizer, train_data, val_data, checkpoint_dir, out_dir, speed_monitor)
  File "/scratch/gilbreth/dchawra/lit-gpt/finetune/adapter_v2.py", line 161, in train
    validate(fabric, model, val_data, tokenizer, longest_seq_length)  # sanity check
  File "/home/dchawra/mambaforge/envs/ml/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    fabric.launch(main, data_dir, checkpoint_dir, out_dir)
  File "/home/dchawra/mambaforge/envs/ml/lib/python3.10/site-packages/lightning/fabric/fabric.py", line 807, in launch
    return func(*args, **kwargs)
  File "/scratch/gilbreth/dchawra/lit-gpt/finetune/adapter_v2.py", line 247, in validate
    return self._wrap_and_launch(function, self, *args, **kwargs)
  File "/home/dchawra/mambaforge/envs/ml/lib/python3.10/site-packages/lightning/fabric/fabric.py", line 889, in _wrap_and_launch
    return to_run(*args, **kwargs)
  File "/home/dchawra/mambaforge/envs/ml/lib/python3.10/site-packages/lightning/fabric/fabric.py", line 894, in _wrap_with_setup
    input_ids, targets = get_batch(fabric, val_data, longest_seq_length)
  File "/scratch/gilbreth/dchawra/lit-gpt/finetune/adapter_v2.py", line 275, in get_batch
    return to_run(*args, **kwargs)
  File "/scratch/gilbreth/dchawra/lit-gpt/finetune/adapter_v2.py", line 140, in main
    ix = torch.randint(len(data), (micro_batch_size,))
TypeError: randint(): argument 'size' (position 2) must be tuple of ints, but found element of type float at pos 0
    train(fabric, model, optimizer, train_data, val_data, checkpoint_dir, out_dir, speed_monitor)
  File "/scratch/gilbreth/dchawra/lit-gpt/finetune/adapter_v2.py", line 161, in train
    validate(fabric, model, val_data, tokenizer, longest_seq_length)  # sanity check
  File "/home/dchawra/mambaforge/envs/ml/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/scratch/gilbreth/dchawra/lit-gpt/finetune/adapter_v2.py", line 247, in validate
    input_ids, targets = get_batch(fabric, val_data, longest_seq_length)
  File "/scratch/gilbreth/dchawra/lit-gpt/finetune/adapter_v2.py", line 275, in get_batch
    ix = torch.randint(len(data), (micro_batch_size,))
TypeError: randint(): argument 'size' (position 2) must be tuple of ints, but found element of type float at pos 0
srun: error: gilbreth-k013: tasks 0-1: Exited with exit code 1
